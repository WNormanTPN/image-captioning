{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inport Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 15:34:18.975018: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734942858.988416  188881 cuda_dnn.cc:8498] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734942858.991979  188881 cuda_blas.cc:1410] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-23 15:34:19.005926: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_captions_file = \"../data/raw/Flickr8k.token.txt\"\n",
    "input_images_dir = \"../data/raw/Flicker8k_Dataset\"\n",
    "\n",
    "input_train_images_file = '../data/raw/Flickr_8k.trainImages.txt'\n",
    "input_val_images_file = '../data/raw/Flickr_8k.devImages.txt'\n",
    "input_test_images_file = '../data/raw/Flickr_8k.testImages.txt'\n",
    "\n",
    "output_captions_file = \"../data/processed/captions.txt\"\n",
    "output_vocab_file = \"../data/processed/vocab.txt\"\n",
    "output_images_dir = \"../data/processed/images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear output directories\n",
    "def clear_output_dirs():\n",
    "    if os.path.exists(output_images_dir):\n",
    "        shutil.rmtree(output_images_dir)\n",
    "    if os.path.exists(output_captions_file):\n",
    "        os.remove(output_captions_file)\n",
    "    if os.path.exists(output_vocab_file):\n",
    "        os.remove(output_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read captions file\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save caption descriptions to a dictionary\n",
    "#id_image : ['caption 1', 'caption 2', 'caption 3',' caption 4', 'caption 5']\n",
    "def load_descriptions(doc):\n",
    "    mapping = dict()\n",
    "    # process lines\n",
    "    for line in doc.split('\\n'):\n",
    "        # split line by white space\n",
    "        tokens = line.split()\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        # take the first token as the image id, the rest as the description\n",
    "        image_id, image_desc = tokens[0], tokens[1:]\n",
    "        # extract filename from image id\n",
    "        image_id = image_id.split('.')[0]\n",
    "        # convert description tokens back to string\n",
    "        image_desc = ' '.join(image_desc)\n",
    "        # create the list if needed\n",
    "        if image_id not in mapping:\n",
    "            mapping[image_id] = list()\n",
    "        # store description\n",
    "        mapping[image_id].append(image_desc)\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text\n",
    "def clean_descriptions(descriptions):\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for i in range(len(desc_list)):\n",
    "            desc = desc_list[i]\n",
    "            # tokenize\n",
    "            desc = desc.split()\n",
    "            # convert to lower case\n",
    "            desc = [word.lower() for word in desc]\n",
    "            # remove punctuation from each token\n",
    "            desc = [w.translate(table) for w in desc]\n",
    "            # remove hanging 's' and 'a'\n",
    "            desc = [word for word in desc if len(word)>1]\n",
    "            # remove tokens with numbers in them\n",
    "            desc = [word for word in desc if word.isalpha()]\n",
    "            # add 'startseq' and 'endseq' to each description\n",
    "            desc.insert(0, 'startseq')\n",
    "            desc.append('endseq')\n",
    "            # store as string\n",
    "            desc_list[i] = ' '.join(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocabulary of descriptions, just get more than 10 times repeated words\n",
    "def get_vocab(descriptions):\n",
    "    vocab = set()\n",
    "    count_vocab = dict()\n",
    "    # Count all words\n",
    "    for desc_list in descriptions.values():\n",
    "        for desc in desc_list:\n",
    "            words = desc.split()\n",
    "            for word in words:\n",
    "                count_vocab[word] = count_vocab.get(word, 0) + 1\n",
    "    # Get words that appear more than 10 times\n",
    "    for word, count in count_vocab.items():\n",
    "        if count >= 10:\n",
    "            vocab.add(word)\n",
    "            \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vocab to file\n",
    "def save_vocab(vocab, filename):\n",
    "    data = '\\n'.join(vocab)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save descriptions to file, one per line\n",
    "def save_descriptions(descriptions, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for key, desc_list in tqdm(descriptions.items()):\n",
    "            for desc in desc_list:\n",
    "                file.write(f\"{key} {desc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing images for inception v3 model\n",
    "def preprocess_image(img):\n",
    "    # Convert all the images to size 299x299 as expected by the inception v3 model\n",
    "    img = image.load_img(img, target_size=(299, 299))\n",
    "    # Convert PIL image to numpy array of 3-dimensions\n",
    "    x = image.img_to_array(img)\n",
    "    # Add one more dimension\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    # preprocess the images using preprocess_input() from inception module\n",
    "    x = preprocess_input(x)\n",
    "    # Convert numpy array to PIL image\n",
    "    x = image.array_to_img(x[0])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed images\n",
    "def save_images(images, folder_name):\n",
    "    for key, image in tqdm(images.items()):\n",
    "        filename = folder_name + key[len(input_images_dir)+1:]\n",
    "        image.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean output directories\n",
    "clear_output_dirs()\n",
    "\n",
    "# Make output directories if they don't exist\n",
    "if not os.path.exists(output_images_dir + '/train'):\n",
    "    os.makedirs(output_images_dir + '/train')\n",
    "if not os.path.exists(output_images_dir + '/val'):\n",
    "    os.makedirs(output_images_dir + '/val')\n",
    "if not os.path.exists(output_images_dir + '/test'):\n",
    "    os.makedirs(output_images_dir + '/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000268201_693b08cb0e.jpg#0\tA child in a pink dress is climbing up a set of stairs in an entry way .\n",
      "1000268201_693b08cb0e.jpg#1\tA girl going into a wooden building .\n",
      "1000268201_693b08cb0e.jpg#2\tA little girl climbing into a wooden playhouse .\n",
      "1000268201_693b08cb0e.jpg#3\tA little girl climbing the s\n"
     ]
    }
   ],
   "source": [
    "doc = load_doc(input_captions_file)\n",
    "print(doc[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 8092 \n"
     ]
    }
   ],
   "source": [
    "descriptions = load_descriptions(doc)\n",
    "print('Loaded: %d ' % len(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A child in a pink dress is climbing up a set of stairs in an entry way .',\n",
       " 'A girl going into a wooden building .',\n",
       " 'A little girl climbing into a wooden playhouse .',\n",
       " 'A little girl climbing the stairs to her playhouse .',\n",
       " 'A little girl in a pink dress going into a wooden cabin .']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq child in pink dress is climbing up set of stairs in an entry way endseq',\n",
       " 'startseq girl going into wooden building endseq',\n",
       " 'startseq little girl climbing into wooden playhouse endseq',\n",
       " 'startseq little girl climbing the stairs to her playhouse endseq',\n",
       " 'startseq little girl in pink dress going into wooden cabin endseq']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean descriptions\n",
    "clean_descriptions(descriptions)\n",
    "descriptions['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and save vocabulary\n",
    "vocab = get_vocab(descriptions)\n",
    "save_vocab(vocab, output_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8092/8092 [00:00<00:00, 584130.32it/s]\n"
     ]
    }
   ],
   "source": [
    "save_descriptions(descriptions, output_captions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = glob.glob(input_images_dir + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 6000\n",
      "Validation images: 1000\n",
      "Test images: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read the train, validation, test image names in a set\n",
    "train_images = set(open(input_train_images_file, 'r').read().strip().split('\\n'))\n",
    "val_images = set(open(input_val_images_file, 'r').read().strip().split('\\n'))\n",
    "test_images = set(open(input_test_images_file, 'r').read().strip().split('\\n'))\n",
    "\n",
    "print('Train images: %d' % len(train_images))\n",
    "print('Validation images: %d' % len(val_images))\n",
    "print('Test images: %d' % len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 6000\n",
      "Validation images: 1000\n",
      "Test images: 1000\n"
     ]
    }
   ],
   "source": [
    "train_img = []\n",
    "val_img = []\n",
    "test_img = []\n",
    "for i in img: # img is list of full path names of all images\n",
    "    if i[len(input_images_dir)+1:] in test_images: # Check if the image belongs to test set\n",
    "        test_img.append(i) # Add it to the list of test images\n",
    "    elif i[len(input_images_dir)+1:] in val_images:\n",
    "        val_img.append(i)\n",
    "    elif i[len(input_images_dir)+1:] in train_images:\n",
    "        train_img.append(i)\n",
    "        \n",
    "print('Train images: %d' % len(train_img))\n",
    "print('Validation images: %d' % len(val_img))\n",
    "print('Test images: %d' % len(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the images\n",
    "train_img = {k: preprocess_image(k) for k in train_img}\n",
    "val_img = {k: preprocess_image(k) for k in val_img}\n",
    "test_img = {k: preprocess_image(k) for k in test_img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:02<00:00, 2545.38it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2549.15it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2537.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save the images\n",
    "save_images(train_img, output_images_dir + '/train/')\n",
    "save_images(val_img, output_images_dir + '/val/')\n",
    "save_images(test_img, output_images_dir + '/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
